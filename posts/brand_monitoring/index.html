<!doctype html>

<html lang="en">

<head>
  
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-M72HGJH');</script>

  <title>Monitor and analyze brands using language models - Diego Hernández Jiménez</title>
  <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="description" content="Kiera: A Hugo theme for creative and technical writing." />
<meta name="author" content="Example" /><meta property="og:title" content="Monitor and analyze brands using language models" />
<meta property="og:description" content="Description I have built a brand monitoring application that leverages both large and specialized smaller language models. The entire application runs on CPU, relying on external APIs for specific tasks, making it a cost-free solution for users." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://diego-hernandez-jimenez.github.io/web/posts/brand_monitoring/" />
<meta property="article:published_time" content="2025-05-23T00:00:00+02:00" />
<meta property="article:modified_time" content="2025-05-23T00:00:00+02:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Monitor and analyze brands using language models"/>
<meta name="twitter:description" content="Description I have built a brand monitoring application that leverages both large and specialized smaller language models. The entire application runs on CPU, relying on external APIs for specific tasks, making it a cost-free solution for users."/>

<meta name="generator" content="Hugo 0.74.3" />
    
    <link rel="shortcut icon" href="https://diego-hernandez-jimenez.github.io/web/images/Dicon.ico" />
  
    <script src="https://diego-hernandez-jimenez.github.io/web/js/mathjax-config.js" defer></script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin="anonymous" />
  <link rel="stylesheet" href="https://diego-hernandez-jimenez.github.io/web/fontawesome/css/all.min.css" />
  
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Slab|Ruda" />
  
  
  <link rel="stylesheet" type="text/css" href="https://diego-hernandez-jimenez.github.io/web/css/styles.css" />
    <script type="text/javascript" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>
    <script type="text/javascript">
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']]
            },
            options: {
                processEscapes: true
            }
        };
    </script>
</head>

<body>
  <div id="container">
    <header>
      <h1>
                <a href="https://diego-hernandez-jimenez.github.io/web/">Diego Hernández Jiménez</a>
            </h1>

      <ul id="social-media">
             <li>
               <a href="https://github.com/Diego-Hernandez-Jimenez" title="GitHub">
               <i class="fab fa-github fa-lg"></i>
               </a>
             </li>
             <li>
               <a href="https://linkedin.com/in/diego-hern%c3%a1ndez-jim%c3%a9nez" title="LinkedIn">
               <i class="fab fa-linkedin fa-lg"></i>
               </a>
             </li>
      </ul>
      
      <p><em>Welcome to my personal website! Here I share some of my little projects.</em></p>
      
    </header>

    
<nav>
    <ul>
        
        <li>
            <a class="" href="https://diego-hernandez-jimenez.github.io/web/tags">
                <i class="fa-li fa  fa-lg"></i><span>Tags</span>
            </a>
        </li>
        
        <li>
            <a class="" href="https://diego-hernandez-jimenez.github.io/web/posts/">
                <i class="fa-li fa  fa-lg"></i><span>Projects</span>
            </a>
        </li>
        
        <li>
            <a class="" href="https://diego-hernandez-jimenez.github.io/web/about/">
                <i class="fa-li fa  fa-lg"></i><span>About</span>
            </a>
        </li>
        
        <li>
            <a class="" href="https://diego-hernandez-jimenez.github.io/web/contact/">
                <i class="fa-li fa  fa-lg"></i><span>Contact</span>
            </a>
        </li>
        
    </ul>
</nav>


    <main>




<article>

    <h1>Monitor and analyze brands using language models</h1>

    
      <aside>
    <ul>
        <li>
            <time class="post-date" datetime="2025-05-23T00:00:00&#43;02:00">May 23, 2025</time>
        </li>
        
        <li>
            Categories:
            <em>
                
                    
                    <a href="https://diego-hernandez-jimenez.github.io/web/categories/projects">Projects</a>
                
            </em>
        </li>
        

        
        <li>
            <em>
                
                    
                    <a href="https://diego-hernandez-jimenez.github.io/web/tags/python">#Python</a>
                
            </em>
        </li>
        

        <li>7 minutes read</li>
    </ul>
</aside>

    

    


    <h4 id="description">Description</h4>
<p>I have built a brand monitoring application that leverages both large and specialized smaller language models. The entire application runs on CPU, relying on external APIs for specific tasks, making it a cost-free solution for users. While this minimizes monetary cost, the reliance on API limits and the absence of GPU acceleration naturally impose limitations on scalability.</p>
<p><img src="https://diego-hernandez-jimenez.github.io/web/images/demo_app_video_x2.gif" alt="brand monitoring tool in action"></p>
<h3 id="why-this-project">Why This Project?</h3>
<p>It all started with an exercise I did some time ago where I explored the capabilities of <code>langchain</code> and <code>langgraph</code> and developed an arbitrary text length summarizer using a small language model on scraped news articles. This experience ignited a desire to expand upon that initial concept, leading to the creation of an app that showcases the versatility and lightweight nature of specialized language models. The result is an effective OSINT (Open-Source Intelligence) tool designed for brand monitoring.</p>
<h3 id="development-workflow">Development Workflow</h3>
<h4 id="1-collecting-articles-from-the-web">1. Collecting Articles from the Web</h4>
<p>My primary tool for gathering news articles was the <strong>NewsAPI</strong>. It offers a highly useful set of filters, allowing for granular control over searches, such as excluding specific media sources, filtering by language, and focusing on matches within titles, descriptions, or the body of articles. However, a notable limitation is its &ldquo;black box&rdquo; nature; there&rsquo;s no transparency regarding the internal search processes or how relevance is calculated when sorting articles. The problem with this is that I loose some control over the generated results. As an example, in the demo app you can see that when searching for &ldquo;Tesla&rdquo; articles, some completely irrelevant articles were included.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># API endpoint and parameters</span>
newsapi_url <span style="color:#f92672">=</span> (
      <span style="color:#e6db74">&#39;https://newsapi.org/v2/everything?&#39;</span>
      f<span style="color:#e6db74">&#39;q={search_query}&#39;</span>
      f<span style="color:#e6db74">&#39;&amp;language={LANG}&#39;</span>
      f<span style="color:#e6db74">&#39;&amp;searchIn={search_in}&#39;</span>
      f<span style="color:#e6db74">&#39;&amp;from={from_date}&#39;</span>
      f<span style="color:#e6db74">&#39;&amp;to={today}&#39;</span>
      f<span style="color:#e6db74">&#39;&amp;excludeDomains={EXCLUDED_SOURCES}&#39;</span>
      <span style="color:#e6db74">&#39;&amp;sortBy=relevancy&#39;</span>
      f<span style="color:#e6db74">&#39;&amp;apiKey={NEWS_API_KEY}&#39;</span>
      )
</code></pre></div><h4 id="2-extracting-content-from-articles">2. Extracting Content from Articles</h4>
<p>A significant discovery during this project was the <strong>Diffbot API</strong>. Beyond its core functionality of extracting content from a given URL, it also provides robust NLP capabilities, including summarization and sentiment scoring. This streamlined my workflow considerably.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># API endpoint and parameters</span>
diffbot_api_url <span style="color:#f92672">=</span> (
        f<span style="color:#e6db74">&#39;https://api.diffbot.com/v3/article?url={url}&#39;</span>
        f<span style="color:#e6db74">&#39;&amp;token={DIFFBOT_API_KEY}&#39;</span>
        f<span style="color:#e6db74">&#39;&amp;naturalLanguage=categories,sentiment,summary&#39;</span>
        f<span style="color:#e6db74">&#39;&amp;summaryNumSentences=4&#39;</span>
        f<span style="color:#e6db74">&#39;&amp;discussion=false&#39;</span>
    )
</code></pre></div><h4 id="3-sentiment-analysis">3. Sentiment Analysis</h4>
<p>Initially, I planned to implement the summarization and sentiment scoring steps myself. However, upon discovering the Diffbot NLP API, I opted to integrate it due to its convenience. By simply adding a few extra parameters to the existing content extraction requests, I obtained excellent results. The major drawback, however, is Diffbot&rsquo;s lack of transparency regarding its NLP API&rsquo;s internal workings. The models used, the processing of full articles versus subsets, and any preprocessing steps remain undisclosed. Besides, there is not much room for customization, something that reduced the possibility of adapting the process to my usecase. Despite this, the quality of the results and the time saved made this a worthwhile compromise.</p>
<h4 id="4-topic-analysis">4. Topic Analysis</h4>
<p>This was arguably one of the most challenging aspects of the project, primarily because I had to make a lot of decisions in terms of implementation. I adopted the <strong>BERTopic</strong> framework, another valuable discovery. This powerful framework comprises several stages:</p>
<ul>
<li>Embed documents: Converting text into numerical representations.</li>
<li>Dimensionality reduction: Reducing the complexity of these embeddings.</li>
<li>Cluster documents: Grouping similar documents together.</li>
<li>Bag-of-words: Creating a representation of word frequency within clusters.</li>
<li>Topic representation: Identifying the set of representative terms and documents of each cluster, as well as assigning meaningful labels to the identified clusters.</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">CustomTokenizer</span>(BaseTokenizer):

  <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">tokenize</span>(self, text: str) <span style="color:#f92672">-&gt;</span> list[str]:
      <span style="color:#e6db74">&#34;&#34;&#34;Apply sklearn regex pattern to extract words&#34;&#34;&#34;</span>

      words <span style="color:#f92672">=</span> findall(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#34;(?u)\b\w\w+\b&#34;</span>, text)
      <span style="color:#66d9ef">return</span> words
      
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">custom_tokenizer</span>(text) <span style="color:#f92672">-&gt;</span> list:
  <span style="color:#e6db74">&#34;&#34;&#34;Custom tokenizer to remove plural nouns (with exceptions) and lemmatize verbs&#34;&#34;&#34;</span>

  plural_exceptions <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#34;police&#34;</span>, <span style="color:#e6db74">&#34;data&#34;</span>, <span style="color:#e6db74">&#34;fish&#34;</span>, <span style="color:#e6db74">&#34;sheep&#34;</span>, <span style="color:#e6db74">&#34;species&#34;</span>, <span style="color:#e6db74">&#34;news&#34;</span>, <span style="color:#e6db74">&#34;media&#34;</span>} <span style="color:#75715e"># exceptions suggested by chatgpt</span>
  blob <span style="color:#f92672">=</span> TextBlob(text, tokenizer<span style="color:#f92672">=</span>CustomTokenizer())

  <span style="color:#66d9ef">return</span> [
      word<span style="color:#f92672">.</span>singularize() <span style="color:#66d9ef">if</span> tag <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;NNS&#39;</span> <span style="color:#f92672">and</span> word <span style="color:#f92672">not</span> <span style="color:#f92672">in</span> plural_exceptions
      <span style="color:#66d9ef">else</span> word<span style="color:#f92672">.</span>lemmatize(pos<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;v&#39;</span>) <span style="color:#66d9ef">if</span> tag<span style="color:#f92672">.</span>startswith(<span style="color:#e6db74">&#39;V&#39;</span>)
      <span style="color:#66d9ef">else</span> word
      <span style="color:#66d9ef">for</span> word,tag <span style="color:#f92672">in</span> blob<span style="color:#f92672">.</span>tags
  ]



<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">initialize_bertopic_components</span>(n_docs: int, random_seed: int) <span style="color:#f92672">-&gt;</span> dict:
  <span style="color:#e6db74">&#34;&#34;&#34;Initializes and returns a dictionary of BERTopic model components.
</span><span style="color:#e6db74">
</span><span style="color:#e6db74">  This function sets up the various models required for BERTopic, including
</span><span style="color:#e6db74">  the embedding model, dimensionality reduction, clustering, vectorization,
</span><span style="color:#e6db74">  c-TF-IDF, and representation models.
</span><span style="color:#e6db74">
</span><span style="color:#e6db74">  Args:
</span><span style="color:#e6db74">      n_docs (int): The number of documents to be processed, used to determine
</span><span style="color:#e6db74">                    the minimum cluster size for HDBSCAN.
</span><span style="color:#e6db74">      random_seed (int): A seed for reproducibility in models that involve
</span><span style="color:#e6db74">                          randomness, such as UMAP.
</span><span style="color:#e6db74">
</span><span style="color:#e6db74">  Returns:
</span><span style="color:#e6db74">      dict: A dictionary containing initialized instances of the BERTopic components:
</span><span style="color:#e6db74">            &#39;embedding_model&#39; (SentenceTransformer),
</span><span style="color:#e6db74">            &#39;dimensionality_reduction_model&#39; (UMAP),
</span><span style="color:#e6db74">            &#39;clustering_model&#39; (HDBSCAN),
</span><span style="color:#e6db74">            &#39;vectorizer_model&#39; (CountVectorizer),
</span><span style="color:#e6db74">            &#39;ctfidf_model&#39; (ClassTfidfTransformer), and
</span><span style="color:#e6db74">            &#39;representation_model&#39; (MaximalMarginalRelevance).
</span><span style="color:#e6db74">  &#34;&#34;&#34;</span>


  <span style="color:#75715e"># Pre-calculate embeddings</span>
  embedding_model <span style="color:#f92672">=</span> SentenceTransformer(EMBEDDING_MODEL)

  <span style="color:#75715e"># Dimensionality Reduction</span>
  dimensionality_reduction_model <span style="color:#f92672">=</span> UMAP(
      n_neighbors<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>,
      n_components<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>,
      min_dist<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0</span>,
      metric<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;cosine&#39;</span>,
      random_state<span style="color:#f92672">=</span>random_seed
  )

  <span style="color:#75715e"># Clustering</span>
  min_size <span style="color:#f92672">=</span> max(int(n_docs <span style="color:#f92672">/</span> <span style="color:#ae81ff">10</span>), <span style="color:#ae81ff">2</span>)
  clustering_model <span style="color:#f92672">=</span> HDBSCAN(
      min_cluster_size<span style="color:#f92672">=</span>min_size,
      metric<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;euclidean&#39;</span>,
      cluster_selection_method<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;eom&#39;</span>,
      prediction_data<span style="color:#f92672">=</span>True
  )

  <span style="color:#75715e"># Vectorize</span>
  vectorizer_model <span style="color:#f92672">=</span> CountVectorizer(
      stop_words<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;english&#39;</span>,
      ngram_range<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>),
      tokenizer<span style="color:#f92672">=</span>custom_tokenizer,
      max_df<span style="color:#f92672">=.</span><span style="color:#ae81ff">95</span>,
      min_df<span style="color:#f92672">=</span><span style="color:#ae81ff">0.05</span>
  )

  <span style="color:#75715e"># c-TF-IDF</span>
  ctfidf_model <span style="color:#f92672">=</span> ClassTfidfTransformer(bm25_weighting<span style="color:#f92672">=</span>True, reduce_frequent_words<span style="color:#f92672">=</span>True)

  <span style="color:#75715e"># Representation Model</span>
  representation_model <span style="color:#f92672">=</span> MaximalMarginalRelevance(diversity<span style="color:#f92672">=</span><span style="color:#ae81ff">0.3</span>)

  <span style="color:#66d9ef">return</span> {
      <span style="color:#e6db74">&#39;embedding_model&#39;</span>: embedding_model,
      <span style="color:#e6db74">&#39;dimensionality_reduction_model&#39;</span>: dimensionality_reduction_model,
      <span style="color:#e6db74">&#39;clustering_model&#39;</span>: clustering_model,
      <span style="color:#e6db74">&#39;vectorizer_model&#39;</span>: vectorizer_model,
      <span style="color:#e6db74">&#39;ctfidf_model&#39;</span>: ctfidf_model,
      <span style="color:#e6db74">&#39;representation_model&#39;</span>: representation_model
  }
</code></pre></div><p>Generating high-quality topics on the first attempt is rarely straightforward. To maximize the likelihood of obtaining discriminative and relevant topics, I meticulously tweaked parameters across all stages of the BERTopic process. Furthermore, for generating clear and concise topic titles, I leveraged the capabilities of Gemma 2 via the Groq API. Take a look to the prompt I wrote for this task to better understand my approach:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">f<span style="color:#e6db74">&#34;&#34;&#34;You are given a topic described by the following keywords: {keywords}. Here are some representative documents related to this topic:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">{representative_docs}
</span><span style="color:#e6db74">
</span><span style="color:#e6db74">  Based on the keywords and documents, provide a concise topic description and nothing else. Keep it under ten words&#34;&#34;&#34;</span>

</code></pre></div><h4 id="4-displaying-results-with-interactive-plots-and-styled-dataframes">4. Displaying Results with Interactive Plots and Styled DataFrames</h4>
<p>The application, despite its limitations, is primarily designed to enhance the visual analysis of brands. Therefore, I focused on presenting the search, sentiment, and topic analysis results in a clear and informative manner, utilizing both tables and plots. For instance, to allow users to access the original source material, I formatted the table displaying article headlines to include clickable URLs. For sentiment results, I used color-coded cells to provide an immediate visual understanding of the overall sentiment.</p>
<p><img src="https://diego-hernandez-jimenez.github.io/web/images/colored_sentiments.png" alt="formatted table"></p>
<p>For plotting, I initially considered using matplotlib or seaborn. However, I quickly realized the importance of interactivity for data exploration. This led me to pivot towards Gradio Plots and finally <em>Altair</em>, which allowed me to create more engaging and interactive visualizations.</p>
<p><img src="https://diego-hernandez-jimenez.github.io/web/images/sentiment_evolution.png" alt="sentiment evolution"></p>
<p><img src="https://diego-hernandez-jimenez.github.io/web/images/scores_and_clusters.png" alt="plots of topic scores and clusters"></p>
<h3 id="deployment--ui">Deployment &amp; UI</h3>
<p>For the application&rsquo;s user interface, I chose Gradio. Its simplicity in syntax for layout organization and its intuitive event handling with Blocks made development efficient. However, after extensive use, I encountered some limitations. Gradio&rsquo;s native plotting options are relatively restricted, and the level of graph customization is limited. While embedding plots generated by other libraries is straightforward, these external plots don&rsquo;t integrate as seamlessly as native Gradio components.</p>
<p><img src="https://diego-hernandez-jimenez.github.io/web/images/brand_monitoring_preview.png" alt="App Preview"></p>
<p>The entire application and its dependencies are containerized using Docker and deployed to Hugging Face Spaces. My experience with Docker for this project involved navigating some changes since my last container creation. Notably, I adopted uv as the Python package manager. Additionally, integrating libraries that require downloading data (such as nltk or Hugging Face models) presented initial challenges. While these issues ultimately proved solvable, they required persistent troubleshooting for a beginner like myself.</p>
<h3 id="final-thoughts">Final Thoughts</h3>
<p>This project sparked several new ideas. One direction involves developing more nuanced methods for analyzing news bias, which could lead to deeper insight into media narratives. Another is expanding the scope of searches beyond specific brands to cover any topic of interest—an approach that holds great potential for OSINT analysts seeking broader situational awareness.</p>
<p>Smaller, specialized language models are very powerful when they&rsquo;re used for tasks perfectly suited to their strengths. It became clear during the project that you don&rsquo;t always need the largest, most complex models like GPT or Gemini. Sometimes, a smaller, focused model is more efficient, and there are even times when traditional NLP methods work best without any LLM at all.</p>
<p>A significant practical limitation was working within API usage quotas and limited hardware resources. Because the app depends on free API plans and CPU-only processing, there are strict caps on the number of requests and the volume of data it can handle. This naturally limits scalability.</p>
<hr>
<p>🚀 Try the chatbot <a href="https://huggingface.co/spaces/bumbledeep/brand-monitoring-tool">here</a>!</p>
<p>The source code in the form of notebook and the data examples can be found <a href="https://github.com/Diego-Hernandez-Jimenez/brand-monitoring-tool/tree/main">here</a>.</p>


</article>


<section class="post-nav">
    <ul>
        
        <li>
            <a href="https://diego-hernandez-jimenez.github.io/web/posts/rag_nato/"><i class="fa fa-chevron-circle-left"></i> Enhancing decision making with RAG chatbot</a>
        </li>
        
        
    </ul>
</section>
  
    
    
  





</main>
    <footer>
        <h6>Copyright &amp; copy; 2023 - Diego Hernández Jiménez |
            Rendered by <a href="https://gohugo.io" title="Hugo">Hugo</a> |
            <a href="https://diego-hernandez-jimenez.github.io/web/index.xml">Subscribe </a></h6>
    </footer>
</div>
<script src="https://diego-hernandez-jimenez.github.io/web/js/scripts.js"></script>

</body>

</html>

