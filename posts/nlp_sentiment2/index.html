<!doctype html>

<html lang="en">

<head>
  
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-M72HGJH');</script>

  <title>NLP with distrowatch reviews. Part II: Sentiment classification - Diego Hernández Jiménez</title>
  <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="description" content="Kiera: A Hugo theme for creative and technical writing." />
<meta name="author" content="Example" /><meta property="og:title" content="NLP with distrowatch reviews. Part II: Sentiment classification" />
<meta property="og:description" content="Description Some time ago, I contemplated transitioning to a Linux-based operating system, driven by my curiosity about the realm of free software and Linux culture. During my exploration, I stumbled upon the Distrowatch website (an invaluable resource offering information about numerous Linux distributions, including reviews)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://diego-hernandez-jimenez.github.io/web/posts/nlp_sentiment2/" />
<meta property="article:published_time" content="2023-08-06T00:00:00+02:00" />
<meta property="article:modified_time" content="2023-08-06T00:00:00+02:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="NLP with distrowatch reviews. Part II: Sentiment classification"/>
<meta name="twitter:description" content="Description Some time ago, I contemplated transitioning to a Linux-based operating system, driven by my curiosity about the realm of free software and Linux culture. During my exploration, I stumbled upon the Distrowatch website (an invaluable resource offering information about numerous Linux distributions, including reviews)."/>

<meta name="generator" content="Hugo 0.74.3" />
    
    <link rel="shortcut icon" href="https://diego-hernandez-jimenez.github.io/web/images/Dicon.ico" />
  
    <script src="https://diego-hernandez-jimenez.github.io/web/js/mathjax-config.js" defer></script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin="anonymous" />
  <link rel="stylesheet" href="https://diego-hernandez-jimenez.github.io/web/fontawesome/css/all.min.css" />
  
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Slab|Ruda" />
  
  
  <link rel="stylesheet" type="text/css" href="https://diego-hernandez-jimenez.github.io/web/css/styles.css" /></head>

<body>
  <div id="container">
    <header>
      <h1>
                <a href="https://diego-hernandez-jimenez.github.io/web/">Diego Hernández Jiménez</a>
            </h1>

      <ul id="social-media">
             <li>
               <a href="https://github.com/Diego-Hernandez-Jimenez" title="GitHub">
               <i class="fab fa-github fa-lg"></i>
               </a>
             </li>
             <li>
               <a href="https://linkedin.com/in/diego-hern%c3%a1ndez-jim%c3%a9nez" title="LinkedIn">
               <i class="fab fa-linkedin fa-lg"></i>
               </a>
             </li>
      </ul>
      
      <p><em>Welcome to my personal website! Here I share some of my little projects.</em></p>
      
    </header>

    
<nav>
    <ul>
        
        <li>
            <a class="" href="https://diego-hernandez-jimenez.github.io/web/tags">
                <i class="fa-li fa  fa-lg"></i><span>Tags</span>
            </a>
        </li>
        
        <li>
            <a class="" href="https://diego-hernandez-jimenez.github.io/web/posts/">
                <i class="fa-li fa  fa-lg"></i><span>Projects</span>
            </a>
        </li>
        
        <li>
            <a class="" href="https://diego-hernandez-jimenez.github.io/web/about/">
                <i class="fa-li fa  fa-lg"></i><span>About</span>
            </a>
        </li>
        
        <li>
            <a class="" href="https://diego-hernandez-jimenez.github.io/web/contact/">
                <i class="fa-li fa  fa-lg"></i><span>Contact</span>
            </a>
        </li>
        
    </ul>
</nav>


    <main>




<article>

    <h1>NLP with distrowatch reviews. Part II: Sentiment classification</h1>

    
      <aside>
    <ul>
        <li>
            <time class="post-date" datetime="2023-08-06T00:00:00&#43;02:00">Aug 6, 2023</time>
        </li>
        
        <li>
            Categories:
            <em>
                
                    
                    <a href="https://diego-hernandez-jimenez.github.io/web/categories/projects">Projects</a>
                
            </em>
        </li>
        

        
        <li>
            <em>
                
                    
                    <a href="https://diego-hernandez-jimenez.github.io/web/tags/python">#Python</a>
                
                    , 
                    <a href="https://diego-hernandez-jimenez.github.io/web/tags/data-analysis">#Data Analysis</a>
                
                    , 
                    <a href="https://diego-hernandez-jimenez.github.io/web/tags/for-fun">#For fun</a>
                
            </em>
        </li>
        

        <li>6 minutes read</li>
    </ul>
</aside>

    

    


    <h3 id="description">Description</h3>
<p>Some time ago, I contemplated transitioning to a Linux-based operating system, driven by my curiosity about the realm of free software and Linux culture. During my exploration, I stumbled upon the <a href="https://distrowatch.com/">Distrowatch</a> website (an invaluable resource offering information about numerous Linux distributions, including reviews). The organized and very structured layout of these reviews, coupled with the inclusion of numerical scores, sparked an idea within me. I envisioned gathering a substantial collection of these reviews—ranging from tens to potentially thousands—and subjecting them to analysis through Natural Language Processing (NLP). Eventually, this idea materialized into a tangible project, the outcome of which can be accessed here.</p>
<p>The project consists of three parts: Web scraping, supervised and unsupervised learning for sentiment analysis. We&rsquo;ve already seen part I, let&rsquo;s continue with sentiment analysis.</p>
<h2 id="problem-definition">Problem definition</h2>
<p>The idea is to predict the rating given by a user using only his/her review as input. However, this might not be as simple as it sounds, We need to clarify one basic assumption: we&rsquo;re going to treat the prediction problem as a classification problem. If we had ratings with scores on a continuous scale with a greater range like 1-100, instead of 1-10, we could think about regression. Another thing to make clear is that, by default, we&rsquo;re going to ignore the order present in ratings (i.e.: 10&gt;8). In the notebook I explore one option to take order into account.</p>
<h2 id="basic-data-exploration">Basic data exploration</h2>
<p>Usually, we&rsquo;d first split the data but because there is no risk of data leakage (I think), we can take a look at the distribution of ratings in the full dataset:</p>
<p><img src="https://diego-hernandez-jimenez.github.io/web/images/class_balance.png" alt="class_distribution"></p>
<p>We&rsquo;ve got 10 unique values and a very skewed distribution, most of the reviews we&rsquo;ve collected are above 8. This translates into the problem of class imbalance.I don&rsquo;t think I have enough expertise or data to treat this problem properly, so we&rsquo;re going to make another assumption to simplify the problem. Given the relative prominence of extreme ratings, we could maybe assume scores are representing some underlying sentiment: negative, positive and maybe neutral. This means that there subsets of scores that belong to the same category (sentiment), but how can we group ratings? Here I&rsquo;ll take a naïve approach and follow &ldquo;common sense&rdquo; (in part III I try other strategies). Here I show three possible options.</p>
<p><img src="https://diego-hernandez-jimenez.github.io/web/images/target_encodings.png" alt="target_encodings"></p>
<p>The first one seems reasonable and let us use binary classification algorithms (in the notebook I compare the performance using different target encoding)</p>
<h2 id="text-pre-processing">Text pre-processing</h2>
<p>Now we&rsquo;re entering the realm of NLP. This is one of my first projects using NLP techniques, so I&rsquo;ll keep it simple.</p>
<ul>
<li>
<p>Tokenization:</p>
<ul>
<li>The tokens (&ldquo;building blocks&rdquo;) of the reviews are the words, more especifically unigrams and bigrams, that is, <em>frustrating</em> can be part of the vocabulary, but also the bigram <em>very frustrating</em>.</li>
<li>Uppercase words are respected in some cases (not acronyms, for instance), because they can denote emphasis.</li>
<li>Digits cannot be tokens (software versions, for example, are not deemed non-informative) except when presented in a format like <em>8/10</em>, because explicit ratings can be very discriminative.</li>
<li>Neither stemming nor lemmatization was applied. As I said, I wanted to keep it simple.</li>
</ul>
</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">preproc_tokenize</span>(review):
  text_rating <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>findall(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\d\/10&#39;</span>,review)
  review_modif <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;(\b[A-Z]{4,}\b)&#39;</span>,<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;upperc\1&#39;</span>,review)
  review_modif <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>sub(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;\d+\.?&#39;</span>,<span style="color:#e6db74">&#39;&#39;</span>,review_modif)
  tokens <span style="color:#f92672">=</span> re<span style="color:#f92672">.</span>findall(<span style="color:#e6db74">r</span><span style="color:#e6db74">&#39;(?u)\b\w\w+\b|[!|?]&#39;</span>,review_modif<span style="color:#f92672">.</span>lower()) <span style="color:#f92672">+</span> text_rating
  <span style="color:#75715e"># stemmed_tokens = [SnowballStemmer(&#39;english&#39;).stem(w) for w in tokens]</span>
  <span style="color:#66d9ef">return</span> tokens

ex <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;xdistrox version 2.04 is a great distro! 8/10. It works in my OS VERY nicely. Why nobody is talking about it??&#39;</span>

<span style="color:#66d9ef">print</span>(ex)
<span style="color:#66d9ef">print</span>(preproc_tokenize(ex))
  
</code></pre></div><pre><code>xdistrox version 2.04 is a great distro! 8/10. It works in my OS VERY nicely. Why nobody is talking about it??
['xdistrox', 'version', 'is', 'great', 'distro', '!', 'it', 'works', 'in', 'my', 'os', 'uppercvery', 'nicely', 'why', 'nobody', 'is', 'talking', 'about', 'it', '?', '?', '8/10']
</code></pre><ul>
<li>
<p>Stop words</p>
<ul>
<li>Some specific words of this context are removed: <em>OS</em>, <em>distro</em>, <em>version</em>, the name of the distributions&hellip;The idea is to reduce the vocabulary size by discarding (supposedly) non-informative words.</li>
<li>I keep some words like <em>very</em> or <em>most</em>, because they can be useful when expessing emotions.</li>
</ul>
</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">
to_keep <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;all&#39;</span>,<span style="color:#e6db74">&#39;any&#39;</span>,<span style="color:#e6db74">&#39;both&#39;</span>,<span style="color:#e6db74">&#39;each&#39;</span>,<span style="color:#e6db74">&#39;few&#39;</span>,<span style="color:#e6db74">&#39;most&#39;</span>,<span style="color:#e6db74">&#39;more&#39;</span>,<span style="color:#e6db74">&#39;only&#39;</span>,<span style="color:#e6db74">&#39;too&#39;</span>,<span style="color:#e6db74">&#39;very&#39;</span>] <span style="color:#75715e"># not</span>
stop <span style="color:#f92672">=</span> [w <span style="color:#66d9ef">for</span> w <span style="color:#f92672">in</span> stopwords<span style="color:#f92672">.</span>words(<span style="color:#e6db74">&#39;english&#39;</span>) <span style="color:#66d9ef">if</span> w <span style="color:#f92672">not</span> <span style="color:#f92672">in</span> to_keep]

extra_stop <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;OS&#39;</span>,<span style="color:#e6db74">&#39;distro&#39;</span>,<span style="color:#e6db74">&#39;LTS&#39;</span>,<span style="color:#e6db74">&#39;version&#39;</span>,<span style="color:#e6db74">&#39;Linux&#39;</span>,<span style="color:#e6db74">&#39;USB&#39;</span>,<span style="color:#e6db74">&#39;PC&#39;</span>]

<span style="color:#75715e"># names were obtained from distrowatch.com using web scraping, see notebook for part 1</span>
<span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#34;distro_names&#34;</span>, <span style="color:#e6db74">&#34;rb&#34;</span>) <span style="color:#66d9ef">as</span> f:
  distro_names <span style="color:#f92672">=</span> load(f)

stop<span style="color:#f92672">.</span>extend(extra_stop)
stop<span style="color:#f92672">.</span>extend(distro_names)

<span style="color:#75715e"># stopwords need to be processed as any other token</span>
stop_tokens <span style="color:#f92672">=</span> preproc_tokenize(<span style="color:#e6db74">&#39; &#39;</span><span style="color:#f92672">.</span>join(stop))
</code></pre></div><ul>
<li>
<p>Vectorization</p>
<ul>
<li>Bag of Words: reviews are represented as vectors of counts with dimension equal to the total number of tokens in the dataset: the vocabulary size. The $i$-th entry of the vector for review $j$ stores the frequency of the $i$-th token of the vocabulary in the review $j$.</li>
</ul>
</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Our Bag of Words vectorizer</span>
bow_vectorizer <span style="color:#f92672">=</span> CountVectorizer(
    lowercase<span style="color:#f92672">=</span>False, <span style="color:#75715e"># transformation to lowercase is done in preproc_tokenize</span>
    tokenizer<span style="color:#f92672">=</span>preproc_tokenize, <span style="color:#75715e"># custom preprocessing and tokenizing function</span>
    stop_words<span style="color:#f92672">=</span>stop_tokens, <span style="color:#75715e"># custom set of stop words</span>
    token_pattern<span style="color:#f92672">=</span>None, <span style="color:#75715e"># ignore, preproc_tokenize takes care</span>
    ngram_range<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">2</span>), <span style="color:#75715e"># unigrams and bigrams</span>
    analyzer<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;word&#39;</span>,
    max_df<span style="color:#f92672">=</span><span style="color:#ae81ff">0.8</span>,
    min_df<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span> <span style="color:#75715e"># tokens have to appear at least in 20 documents -&gt; this reduces the number of features drastically</span>
)
</code></pre></div><p>Our token distribution looks like this:</p>
<p><img src="https://diego-hernandez-jimenez.github.io/web/images/token_dist.png" alt="token_distribution_by_class"></p>
<h2 id="model-training-and-selection">Model training and selection</h2>
<p>For this section I haven&rsquo;t done a careful search to find the best algorithm. I wanted to try the Naïve Bayes model because its simplicity and because it doesn&rsquo;t require hyper-parameter tuning.</p>
<p>Classification rule: $\hat c=\underset{c\in K}{\operatorname{argmax}} P(c)\prod_{i=1}^{|V|} P(w_i|c)$</p>
<p>Where $c$ represents each of the $k$ classes, $w_i$ is the $i$-th token of the vocabulary set $V$, with size $|V|$</p>
<p>I compared the basic version, Multinomial Naïve Bayes Classifier (MNB), and the Complement Naïve Bayes Classifier (CNB), which is something like a improved version of MNB. I performed 5-cross-validation and used balanced accuracy for model selection, because it&rsquo;s less misguiding in the presence of class imbalance than accuracy (or even AUC, as I&rsquo;ve seen in other projects). With an average balanced accuracy of 0.813, CNB beat MNB, which obtained 0.801, so I chose the former as the final model.</p>
<p>However, those are cross-validation performance scores, and we need to see how well the final model performs on unseen data. The results for the test set are the following.</p>
<p><img src="https://diego-hernandez-jimenez.github.io/web/images/confmat_test.png" alt="confusion_matrix"></p>
<p>With global accuracy of 0.867 and balanced accuracy of 0.85.</p>
<p>Not bad, but far from excellent, a non-negiglible 18% of &ldquo;negative&rdquo; reviews are predicted as positive (maybe because of reviews on the border, those with rating of 5 or 6).</p>
<h2 id="which-tokens-are-most-relevant-for-classification">Which tokens are most relevant for classification?</h2>
<p>The probability of a class is given by the review $d$ is</p>
<p>$P(c|d)=P(c)\prod_{i=1}^{|V_d|} P(w_i|c)$</p>
<p>where $w_i$ now represents the tokens present in review $d$ with vocabulary $V_d$, a subset of $V$</p>
<p>If we take the log:</p>
<p>$\log P(c|d)=\log P(c)+\sum_{i=1}^{|V_d|} \log P(w_i|c)$</p>
<p>It&rsquo;s easier to see now that, as happens with linear regression, the bigger the value of $\log P(w_i|c)$, the greater importance the token $w_i$ has for predictions.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">top_tokens <span style="color:#f92672">=</span> <span style="color:#ae81ff">15</span>
neg_prob_sorted <span style="color:#f92672">=</span> final_model[<span style="color:#e6db74">&#39;clf&#39;</span>]<span style="color:#f92672">.</span>feature_log_prob_[<span style="color:#ae81ff">0</span>, :]<span style="color:#f92672">.</span>argsort()[::<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]
pos_prob_sorted <span style="color:#f92672">=</span> final_model[<span style="color:#e6db74">&#39;clf&#39;</span>]<span style="color:#f92672">.</span>feature_log_prob_[<span style="color:#ae81ff">1</span>, :]<span style="color:#f92672">.</span>argsort()[::<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]

<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;negative reviews&#39;</span>)
<span style="color:#66d9ef">print</span>(np<span style="color:#f92672">.</span>take(final_model[<span style="color:#e6db74">&#39;vectorizer&#39;</span>]<span style="color:#f92672">.</span>get_feature_names_out(), neg_prob_sorted[:top_tokens]),<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>)

<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;positive reviews&#39;</span>)
<span style="color:#66d9ef">print</span>(np<span style="color:#f92672">.</span>take(final_model[<span style="color:#e6db74">&#39;vectorizer&#39;</span>]<span style="color:#f92672">.</span>get_feature_names_out(), pos_prob_sorted[:top_tokens]))

</code></pre></div><pre><code>negative reviews
['worst' 'sad' 'terrible' 'tried install' 'way too' 'shame' 'asks'
 'asking' 'pass' 'previous versions' 'problematic' 'tries' 'failure'
 'parts' 'get things'] 

positive reviews
['configurable' 'pleased' 'charm' 'well done' 'snapshots' 'upgraded'
 'intel core' 'enjoying' 'unix' 'underrated' 'impressive' 'period'
 'most stable' 'much easier' 'favourite']
 
</code></pre><p>Very revealing indeed. For example, when a user mentions problems with the installation process or mentions previous versions of the software, the review is probably going to be negative. On the other hand, comments about how configurable and stable is the linux distribution predict positive reviews.</p>
<p>If you want to know more about the project, check the part I and III. All the code can be found <a href="https://github.com/Diego-Hernandez-Jimenez/nlp_distrowatch/tree/main">here</a>.</p>


</article>


<section class="post-nav">
    <ul>
        
        <li>
            <a href="https://diego-hernandez-jimenez.github.io/web/posts/sql_imdb/"><i class="fa fa-chevron-circle-left"></i> SQL and Python to explore IMDb movies</a>
        </li>
        
        
        <li>
            <a href="https://diego-hernandez-jimenez.github.io/web/posts/nlp_sentiment1/">NLP with distrowatch reviews. Part I: Web scraping <i class="fa fa-chevron-circle-right"></i> </a>
        </li>
        
    </ul>
</section>
  
    
    
  





</main>
    <footer>
        <h6>Copyright &amp; copy; 2020 - Diego Hernández Jiménez |
            Rendered by <a href="https://gohugo.io" title="Hugo">Hugo</a> |
            <a href="https://diego-hernandez-jimenez.github.io/web/index.xml">Subscribe </a></h6>
    </footer>
</div>
<script src="https://diego-hernandez-jimenez.github.io/web/js/scripts.js"></script>

</body>

</html>

