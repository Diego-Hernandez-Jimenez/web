<!doctype html>

<html lang="en">

<head>
  
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-M72HGJH');</script>

  <title>Enhancing decision making with RAG chatbot - Diego HernÃ¡ndez JimÃ©nez</title>
  <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="description" content="Kiera: A Hugo theme for creative and technical writing." />
<meta name="author" content="Example" /><meta property="og:title" content="Enhancing decision making with RAG chatbot" />
<meta property="og:description" content="Description I recently built an AI-powered virtual assistant specializing in NATO&rsquo;s Alternative Analysis (AltA) methodology. This chatbot leverages Large Language Models (LLMs) combined with Retrieval-Augmented Generation (RAG) to provide accurate responses to questions that general-purpose models might struggle with." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://diego-hernandez-jimenez.github.io/web/posts/rag_nato/" />
<meta property="article:published_time" content="2024-12-11T00:00:00+01:00" />
<meta property="article:modified_time" content="2024-12-11T00:00:00+01:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Enhancing decision making with RAG chatbot"/>
<meta name="twitter:description" content="Description I recently built an AI-powered virtual assistant specializing in NATO&rsquo;s Alternative Analysis (AltA) methodology. This chatbot leverages Large Language Models (LLMs) combined with Retrieval-Augmented Generation (RAG) to provide accurate responses to questions that general-purpose models might struggle with."/>

<meta name="generator" content="Hugo 0.74.3" />
    
    <link rel="shortcut icon" href="https://diego-hernandez-jimenez.github.io/web/images/Dicon.ico" />
  
    <script src="https://diego-hernandez-jimenez.github.io/web/js/mathjax-config.js" defer></script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin="anonymous" />
  <link rel="stylesheet" href="https://diego-hernandez-jimenez.github.io/web/fontawesome/css/all.min.css" />
  
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Slab|Ruda" />
  
  
  <link rel="stylesheet" type="text/css" href="https://diego-hernandez-jimenez.github.io/web/css/styles.css" />
    <script type="text/javascript" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>
    <script type="text/javascript">
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']]
            },
            options: {
                processEscapes: true
            }
        };
    </script>
</head>

<body>
  <div id="container">
    <header>
      <h1>
                <a href="https://diego-hernandez-jimenez.github.io/web/">Diego HernÃ¡ndez JimÃ©nez</a>
            </h1>

      <ul id="social-media">
             <li>
               <a href="https://github.com/Diego-Hernandez-Jimenez" title="GitHub">
               <i class="fab fa-github fa-lg"></i>
               </a>
             </li>
             <li>
               <a href="https://linkedin.com/in/diego-hern%c3%a1ndez-jim%c3%a9nez" title="LinkedIn">
               <i class="fab fa-linkedin fa-lg"></i>
               </a>
             </li>
      </ul>
      
      <p><em>Welcome to my personal website! Here I share some of my little projects.</em></p>
      
    </header>

    
<nav>
    <ul>
        
        <li>
            <a class="" href="https://diego-hernandez-jimenez.github.io/web/tags">
                <i class="fa-li fa  fa-lg"></i><span>Tags</span>
            </a>
        </li>
        
        <li>
            <a class="" href="https://diego-hernandez-jimenez.github.io/web/posts/">
                <i class="fa-li fa  fa-lg"></i><span>Projects</span>
            </a>
        </li>
        
        <li>
            <a class="" href="https://diego-hernandez-jimenez.github.io/web/about/">
                <i class="fa-li fa  fa-lg"></i><span>About</span>
            </a>
        </li>
        
        <li>
            <a class="" href="https://diego-hernandez-jimenez.github.io/web/contact/">
                <i class="fa-li fa  fa-lg"></i><span>Contact</span>
            </a>
        </li>
        
    </ul>
</nav>


    <main>




<article>

    <h1>Enhancing decision making with RAG chatbot</h1>

    
      <aside>
    <ul>
        <li>
            <time class="post-date" datetime="2024-12-11T00:00:00&#43;01:00">Dec 11, 2024</time>
        </li>
        
        <li>
            Categories:
            <em>
                
                    
                    <a href="https://diego-hernandez-jimenez.github.io/web/categories/projects">Projects</a>
                
            </em>
        </li>
        

        
        <li>
            <em>
                
                    
                    <a href="https://diego-hernandez-jimenez.github.io/web/tags/python">#Python</a>
                
            </em>
        </li>
        

        <li>4 minutes read</li>
    </ul>
</aside>

    

    


    <h4 id="description">Description</h4>
<p>I recently built an AI-powered virtual assistant specializing in NATO&rsquo;s Alternative Analysis (AltA) methodology. This chatbot leverages Large Language Models (LLMs) combined with Retrieval-Augmented Generation (RAG) to provide accurate responses to questions that general-purpose models might struggle with. The system is built using LangChain, Chroma, and the Groq API, while the user interface is developed with Streamlit. The application is deployed on Hugging Face Spaces as a Docker container. <a href="https://huggingface.co/spaces/bumbledeep/RAG-NATO-chatbot">Check it out here</a>.</p>
<p><img src="https://diego-hernandez-jimenez.github.io/web/images/rag_nato_preview2.png" alt="Chatbot Preview"></p>
<h3 id="why-this-project">Why This Project?</h3>
<ol>
<li><strong>Challenging and Niche</strong> â€“ The specificity of this topic made the project uniquely demanding. A standard chatbot using only an LLM would struggle due to the lack of specialized knowledge.</li>
<li><strong>Background in Psychology</strong> â€“ My interest in human decision-making naturally led me to this project.</li>
<li><strong>Interest in Technology &amp; Military Topics</strong> â€“ This project provided an opportunity to explore NATO methodologies while enhancing my technical skills.</li>
</ol>
<hr>
<h3 id="development-workflow">Development workflow</h3>
<h4 id="1-extracting-and-preprocessing-text">1. Extracting and preprocessing text</h4>
<ul>
<li>
<p>The first step was obtaining and converting the AltA methodology handbook from PDF to plain text.</p>
</li>
<li>
<p>Parsing the PDF was particularly challenging due to its structured content but complex formatting.</p>
</li>
</ul>
<p><img src="https://diego-hernandez-jimenez.github.io/web/images/example_alta_handbook_format.png" alt="Original PDF Format"></p>
<ul>
<li>
<p>Initially, I used PyPDF with custom preprocessing functions, but the results were suboptimalâ€”some words were broken due to line breaks, and the hierarchical structure was lost.</p>
</li>
<li>
<p>Fortunately, I discovered <strong>MinerU</strong>, a recently developed tool for PDF parsing, which significantly improved extraction quality. This tool preserved the original structure and formatted content into markdown, making the next steps much smoother (chek it out <a href="https://mineru.readthedocs.io/en/latest/">here</a>, it&rsquo;s pretty good!).</p>
</li>
</ul>
<p><img src="https://diego-hernandez-jimenez.github.io/web/images/minerU_demo_hf.png" alt="MinerU demo in Hugging Face"></p>
<h4 id="2-chunking--vectorization">2. Chunking &amp; vectorization</h4>
<p>The extracted text needed to be divided into meaningful chunks before being transformed into vector representations for retrieval. Early on, this was a complex process:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e"># Splitter applied to chapters dedicated to techniques</span>
techniques_splitter <span style="color:#f92672">=</span> RecursiveCharacterTextSplitter(
    separators<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">What to use it for</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>, <span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">Application</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#39;</span>, <span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">Example&#39;</span>, <span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">Challenges&#39;</span>, <span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">Hints and tips&#39;</span>, <span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">Further reading&#39;</span>, <span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">&#39;</span>],
    keep_separator<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;start&#39;</span>,
    chunk_size<span style="color:#f92672">=</span><span style="color:#ae81ff">300</span>,
    chunk_overlap<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>,
    length_function<span style="color:#f92672">=</span>len,
    add_start_index<span style="color:#f92672">=</span>True,
)

<span style="color:#75715e"># Splitter applied to chapter dedicated to glossary</span>
glossary_splitter <span style="color:#f92672">=</span> RecursiveCharacterTextSplitter(
    separators<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#39;</span><span style="color:#ae81ff">\n\n</span><span style="color:#e6db74">&#39;</span>],
    keep_separator<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;end&#39;</span>,
    chunk_size<span style="color:#f92672">=</span><span style="color:#ae81ff">300</span>,
    chunk_overlap<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>,
    length_function<span style="color:#f92672">=</span>len,
    add_start_index<span style="color:#f92672">=</span>True,
)

</code></pre></div><p>However, with <strong>MinerU</strong>, the process was dramatically simplified:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">headers_to_split_on <span style="color:#f92672">=</span> [
    (<span style="color:#e6db74">&#34;#&#34;</span>, <span style="color:#e6db74">&#34;Topic 1&#34;</span>),
    (<span style="color:#e6db74">&#34;##&#34;</span>, <span style="color:#e6db74">&#34;Topic 2&#34;</span>),
    (<span style="color:#e6db74">&#34;###&#34;</span>, <span style="color:#e6db74">&#34;Topic 3&#34;</span>),
]

markdown_splitter <span style="color:#f92672">=</span> MarkdownHeaderTextSplitter(headers_to_split_on, strip_headers<span style="color:#f92672">=</span>False)
md_header_splits <span style="color:#f92672">=</span> markdown_splitter<span style="color:#f92672">.</span>split_text(markdown_document)[<span style="color:#ae81ff">6</span>:] <span style="color:#75715e"># Discard first 6 chunks (cover, index)</span>
</code></pre></div><p>This improved retrieval quality, especially for single-topic queries. Additionally, switching to <strong>Gemini 1.5</strong> for embeddings further enhanced performance, replacing initial attempts with Sentence Transformers models.</p>
<h4 id="3-building-the-rag-system">3. Building the RAG system</h4>
<ul>
<li>The user query is used to search for the <strong>k</strong> most relevant vectors in the database.</li>
<li>These retrieved vectors serve as context for the LLM, ensuring accurate responses.</li>
<li><strong>Prompt tuning</strong> was crucial for improving results.</li>
<li>I selected <strong>Mixtral-8x7B</strong> (from Groq API) as the core LLM due to its strong performance (there other models available in the app if you want to play with them). (*Update: a few weeks after deploying the app, Mixtral-8x7B was deprecated in Groq, so it no longer appears as an option)</li>
</ul>
<p>One key challenge was <strong>chat memory</strong>. In a naive RAG implementation, the chatbot does not retain conversational context. For example:</p>
<ul>
<li><strong>User:</strong> &ldquo;What is AltA?&rdquo;</li>
<li><strong>User:</strong> &ldquo;How can I apply it?&rdquo;</li>
<li>The system fails to understand that &ldquo;it&rdquo; refers to AltA.</li>
</ul>
<p>To fix this, I implemented <strong>memory-aware retrieval</strong> using a rephraser LLM that reformulated queries by incorporating recent conversation history.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">rephrase_template <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;&#34;You are a query rephraser. Given a chat history and the latest user query, rephrase the query if it implicitly references topics in the chat history.
</span><span style="color:#e6db74">If the query does not reference the chat history, return it as is. Do not provide explanations, just return the rephrased or original query.
</span><span style="color:#e6db74">Chat history:
</span><span style="color:#e6db74">{chat_history}
</span><span style="color:#e6db74">Latest user query:
</span><span style="color:#e6db74">{input}
</span><span style="color:#e6db74">&#34;&#34;&#34;</span>
</code></pre></div><p>With this improvement, the chatbot correctly reformulates ambiguous queries before retrieving relevant information.</p>
<hr>
<h3 id="deployment--ui">Deployment &amp; UI</h3>
<p>I used <strong>Streamlit</strong> for the UI, making development straightforward despite some challenges when testing in Google Colab.</p>
<p>For deployment, I opted for an approach with intermediate difficulty:</p>
<ul>
<li>I created a dockerfile and uploaded all the necessary files to <strong>Hugging Face Spaces</strong>, where a docker container with the packaged application was automatically built and deployed.</li>
<li>This approach offers more flexibility than <strong>Streamlit Cloud</strong>, making it reusable for future projects.</li>
</ul>
<hr>
<h3 id="final-thoughts">Final thoughts</h3>
<p>This project was an exciting dive into RAG-based chatbots, PDF parsing, and deployment strategies. It also reinforced the importance of structuring and preprocessing text efficiently for high-quality retrieval. Future improvements could include fine-tuning models further and experimenting with alternative memory mechanisms.</p>
<p>ðŸš€ Try the chatbot <a href="https://huggingface.co/spaces/bumbledeep/RAG-NATO-chatbot">here</a>!</p>
<p>The source code, data and notebooks using for this project can be found <a href="https://github.com/Diego-Hernandez-Jimenez/RAG_NATO_streamlit">here</a></p>


</article>


<section class="post-nav">
    <ul>
        
        <li>
            <a href="https://diego-hernandez-jimenez.github.io/web/posts/lvq2/"><i class="fa fa-chevron-circle-left"></i> Prototype-based learning. Part II: LVQ family of models in PyTorch</a>
        </li>
        
        
        <li>
            <a href="https://diego-hernandez-jimenez.github.io/web/posts/brand_monitoring/">Monitor and analyze brands using language models <i class="fa fa-chevron-circle-right"></i> </a>
        </li>
        
    </ul>
</section>
  
    
    
  





</main>
    <footer>
        <h6>Copyright &amp; copy; 2023 - Diego HernÃ¡ndez JimÃ©nez |
            Rendered by <a href="https://gohugo.io" title="Hugo">Hugo</a> |
            <a href="https://diego-hernandez-jimenez.github.io/web/index.xml">Subscribe </a></h6>
    </footer>
</div>
<script src="https://diego-hernandez-jimenez.github.io/web/js/scripts.js"></script>

</body>

</html>

